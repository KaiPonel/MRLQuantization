{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":3855,"status":"ok","timestamp":1723654104229,"user":{"displayName":"Kai Ponel","userId":"09877000230544749752"},"user_tz":-120},"id":"DovlhcyLrdNW"},"outputs":[],"source":["import os\n","import json\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import seaborn as sns\n","import pandas as pd\n","import copy\n","from IPython.display import display\n","pd.set_option('display.max_columns', None)\n","pd.set_option('display.max_rows', None)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17971,"status":"ok","timestamp":1723654122199,"user":{"displayName":"Kai Ponel","userId":"09877000230544749752"},"user_tz":-120},"id":"juRYqL7ud71g","outputId":"854cab4e-b032-42ed-8b03-76258f0e2d39"},"outputs":[],"source":["from google.colab import drive\n","\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1723654122199,"user":{"displayName":"Kai Ponel","userId":"09877000230544749752"},"user_tz":-120},"id":"PB5Qywy_d8GP"},"outputs":[],"source":["BASE_PATH = \"/content/drive/MyDrive/BachelorThesisResults\"\n","DEFAULT_OFFSET_PATH = \"no_model_name_available/no_revision_available\"\n","GLOBAL_SAVE_DIR = \"/content/drive/MyDrive/BachelorThesisResults/tables\""]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1723654122199,"user":{"displayName":"Kai Ponel","userId":"09877000230544749752"},"user_tz":-120},"id":"CeOdjNdX95BG"},"outputs":[],"source":["tasks_dict = {\n","    \"classification\": [\n","        \"Banking77Classification\",\n","        \"EmotionClassification\",\n","        \"TweetSentimentExtractionClassification\",\n","        \"AmazonCounterfactualClassification\",\n","        \"MassiveIntentClassification\",\n","        \"MassiveScenarioClassification\",\n","        \"MTOPDomainClassification\",\n","        \"MTOPIntentClassification\"\n","    ],\n","    \"clustering\": [\n","        \"ArXivHierarchicalClusteringP2P\",\n","        \"ArXivHierarchicalClusteringS2S\",\n","        \"BiorxivClusteringP2P.v2\",\n","        \"BiorxivClusteringS2S.v2\",\n","        \"MedrxivClusteringP2P.v2\",\n","        \"MedrxivClusteringS2S.v2\",\n","        \"RedditClustering.v2\",\n","        \"StackExchangeClustering.v2\",\n","        \"StackExchangeClusteringP2P.v2\",\n","        \"TwentyNewsgroupsClustering.v2\",\n","    ],\n","    \"sts\": [\n","        \"BIOSSES\",\n","        \"SICK-R\",\n","        \"STS12\",\n","        \"STS13\",\n","        \"STS14\",\n","        \"STS15\",\n","        \"STS16\",\n","        \"STSBenchmark\",\n","        \"STS17\",\n","        \"STS22\",\n","    ],\n","    \"pairclass\": [\n","        \"SprintDuplicateQuestions\",\n","        \"TwitterSemEval2015\",\n","        \"TwitterURLCorpus\",\n","    ],\n","    \"retrieval\": [\n","        \"ArguAna\",\n","        \"CQADupstackWebmastersRetrieval\",\n","        \"NFCorpus\",\n","    ],\n","    \"rerank\": [\n","        \"AskUbuntuDupQuestions\",\n","        \"MindSmallReranking\",\n","        \"StackOverflowDupQuestions\"\n","    ],\n","    \"summ\": [\n","        \"SummEval\"\n","    ],\n","    \"all\": [\n","        \"Banking77Classification\",\n","        \"EmotionClassification\",\n","        \"TweetSentimentExtractionClassification\",\n","        \"AmazonCounterfactualClassification\",\n","        \"MassiveIntentClassification\",\n","        \"MassiveScenarioClassification\",\n","        \"MTOPDomainClassification\",\n","        \"MTOPIntentClassification\",\n","        \"ArXivHierarchicalClusteringP2P\",\n","        \"ArXivHierarchicalClusteringS2S\",\n","        \"BiorxivClusteringP2P.v2\",\n","        \"BiorxivClusteringS2S.v2\",\n","        \"MedrxivClusteringP2P.v2\",\n","        \"MedrxivClusteringS2S.v2\",\n","        \"RedditClustering.v2\",\n","        \"StackExchangeClustering.v2\",\n","        \"StackExchangeClusteringP2P.v2\",\n","        \"TwentyNewsgroupsClustering.v2\",\n","        \"BIOSSES\",\n","        \"SICK-R\",\n","        \"STS12\",\n","        \"STS13\",\n","        \"STS14\",\n","        \"STS15\",\n","        \"STS16\",\n","        \"STSBenchmark\",\n","        \"STS17\",\n","        \"STS22\",\n","        \"SprintDuplicateQuestions\",\n","        \"TwitterSemEval2015\",\n","        \"TwitterURLCorpus\",\n","        \"ArguAna\",\n","        \"CQADupstackWebmastersRetrieval\",\n","        \"NFCorpus\",\n","        \"AskUbuntuDupQuestions\",\n","        \"MindSmallReranking\",\n","        \"StackOverflowDupQuestions\",\n","        \"SummEval\"\n","    ]\n","}"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1723654122199,"user":{"displayName":"Kai Ponel","userId":"09877000230544749752"},"user_tz":-120},"id":"wi-6vp3eCdEq"},"outputs":[],"source":["tasks_dict_mapping = {\n","    \"CLA\": [\n","        \"Banking77Classification\",\n","        \"EmotionClassification\",\n","        \"TweetSentimentExtractionClassification\",\n","        \"AmazonCounterfactualClassification\",\n","        \"MassiveIntentClassification\",\n","        \"MassiveScenarioClassification\",\n","        \"MTOPDomainClassification\",\n","        \"MTOPIntentClassification\"\n","    ],\n","    \"CLU\": [\n","        \"ArXivHierarchicalClusteringP2P\",\n","        \"ArXivHierarchicalClusteringS2S\",\n","        \"BiorxivClusteringP2P.v2\",\n","        \"BiorxivClusteringS2S.v2\",\n","        \"MedrxivClusteringP2P.v2\",\n","        \"MedrxivClusteringS2S.v2\",\n","        \"RedditClustering.v2\",\n","        \"StackExchangeClustering.v2\",\n","        \"StackExchangeClusteringP2P.v2\",\n","        \"TwentyNewsgroupsClustering.v2\",\n","    ],\n","    \"STS\": [\n","        \"BIOSSES\",\n","        \"SICK-R\",\n","        \"STS12\",\n","        \"STS13\",\n","        \"STS14\",\n","        \"STS15\",\n","        \"STS16\",\n","        \"STSBenchmark\",\n","        \"STS17\",\n","        \"STS22\",\n","    ],\n","    \"PCL\": [\n","        \"SprintDuplicateQuestions\",\n","        \"TwitterSemEval2015\",\n","        \"TwitterURLCorpus\",\n","    ],\n","    \"RET\": [\n","        \"ArguAna\",\n","        \"CQADupstackWebmastersRetrieval\",\n","        \"NFCorpus\",\n","    ],\n","    \"RER\": [\n","        \"AskUbuntuDupQuestions\",\n","        \"MindSmallReranking\",\n","        \"StackOverflowDupQuestions\"\n","    ],\n","    \"SUM\": [\n","        \"SummEval\"\n","    ]}"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1723654122199,"user":{"displayName":"Kai Ponel","userId":"09877000230544749752"},"user_tz":-120},"id":"hqhmN_n0BKI9"},"outputs":[],"source":["def replace_table_headers(headers, tasks_dict_mapping):\n","    new_headers = []\n","    for header in headers:\n","        replaced = False\n","        for key, tasks in tasks_dict_mapping.items():\n","            if header in tasks:\n","                index = tasks.index(header) + 1   \n","                new_header = f\"{key}\\\\\\\\{index}\"\n","                new_headers.append(new_header)\n","                replaced = True\n","                break\n","        if not replaced:\n","            new_headers.append(header)  \n","    return new_headers\n","\n","def dataframe_to_latex(df, test_type, model_name, precision=4, make_table_tiny=True, caption=\"Placeholder\", custom_name=None, replace_relative=False):\n","\n","    df = copy.deepcopy(df)\n","\n","    if replace_relative:\n","      df.columns = [col.replace('Relative_', '') for col in df.columns]\n","\n","    # Replace the column names using the replace_table_headers function\n","    df.columns = replace_table_headers(df.columns, tasks_dict_mapping)\n","\n","    # Rename \"Dimensionality\" to \"Dim.\"\n","    df.columns = ['d' if col == 'Dimensionality' else col for col in df.columns]\n","\n","    # Rename \"Quantization Technique\" to \"Quant.\\\\Tech.\"\n","    df.columns = ['q' if col == 'Quantization Technique' else col for col in df.columns]\n","\n","    df.columns = [\"l\" if col==\"Inference Layer\" else col for col in df.columns]\n","\n","    df.columns = [\"req. bits\" if col=='Memory Used (bits)' else col for col in df.columns]\n","\n","     # Apply shortening to the \"q\" column values\n","    if 'q' in df.columns:\n","        df['q'] = df['q'].replace({\n","            'float32': 'f32',\n","            'binary': 'bin',\n","            'int8': 'int'\n","        })\n","\n","    # Apply rounding to all float values in the dataframe\n","    df = df.applymap(lambda x: f\"{x:.{precision}f}\" if isinstance(x, float) else x)\n","\n","    # Prepare the column names for LaTeX with makecell and escape underscores\n","    df.columns = [r'\\makecell{' + col.replace('_', r'\\\\').replace(' ', r'\\\\') + '}' for col in df.columns]\n","\n","    # Generate LaTeX string from DataFrame\n","    latex_str = df.to_latex(index=False, escape=False)\n","\n","    # Table label\n","    table_label = f\"table_app:{model_name}_{test_type}\"\n","\n","    # Format the table only if make_table_tiny is True\n","    if make_table_tiny:\n","        latex_str = f\"\"\"\n","    \\\\begin{{table}}[H]\n","    \\\\hspace*{{-1.5cm}}\n","    \\\\setlength{{\\\\tabcolsep}}{{1pt}} % Reduce horizontal cell padding\n","    \\\\renewcommand{{\\\\arraystretch}}{{0.75}} % Reduce vertical cell padding\n","    \\\\tiny % Smaller font size\n","    \\\\setcellgapes{{1pt}} % Reduce the cell gaps set earlier\n","    \\\\makegapedcells\n","    \\\\centering\n","    {latex_str.splitlines()[0]} \\\\\\\\\n","    {' '.join(latex_str.splitlines()[1:])}\n","    \\\\caption{{{caption}}}\n","    \\\\label{{{table_label}}}\n","    \\\\end{{table}}\n","    \"\"\"\n","    else:\n","        latex_str = f\"\"\"\n","    \\\\begin{{table}}[ht]\n","    \\\\centering\n","    \\\\begin{{tabular}}{{lrlllllllllllllllllllllllllllllllllllllllllllllll}}\n","    \\\\toprule\n","    {latex_str.splitlines()[0]} \\\\\\\\\n","    \\\\midrule\n","    {' '.join(latex_str.splitlines()[1:])}\n","    \\\\bottomrule\n","    \\\\end{{tabular}}\n","    \\\\caption{{Your caption here}}\n","    \\\\label{{{table_label}}}\n","    \\\\end{{table}}\n","    \"\"\"\n","\n","    directory = os.path.join(GLOBAL_SAVE_DIR, test_type, model_name)\n","    os.makedirs(directory, exist_ok=True)\n","\n","    if not custom_name:\n","      file_path = os.path.join(directory, f\"{model_name}.tex\")\n","    else:\n","      file_path = os.path.join(directory, f\"{model_name}_{custom_name}.tex\")\n","\n","    with open(file_path, 'w') as f:\n","        f.write(latex_str)\n","    print(latex_str)\n","\n","    return latex_str\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1723654122199,"user":{"displayName":"Kai Ponel","userId":"09877000230544749752"},"user_tz":-120},"id":"USk8FlEmJL8i"},"outputs":[],"source":["models_dict = {\n","    \"nomic-embed-text-v1.5\": {\n","        \"path\": f\"{BASE_PATH}/v1/nomic-ai\",\n","        \"dims\": [768, 512, 256, 128, 64, 32, 16, 8],\n","        \"quantization_techniques\": [\"float32\", \"int8\", \"binary\"],\n","        \"offset_path\": DEFAULT_OFFSET_PATH\n","    },\n","    \"mxbai-embed-large-v1\": {\n","        \"path\": f\"{BASE_PATH}/v1/mixedbread-ai\",\n","        \"dims\": [1024, 512, 256, 128, 64, 32, 16, 8],\n","        \"quantization_techniques\": [\"float32\", \"int8\", \"binary\"],\n","        \"offset_path\": DEFAULT_OFFSET_PATH\n","    },\n","    \"stella_en_400M_v5\": {\n","        \"path\": f\"{BASE_PATH}/v1/dunzhang\",\n","        \"dims\": [8192, 4096, 2048, 1024, 512, 256, 128, 64],\n","        \"quantization_techniques\": [\"float32\", \"int8\", \"binary\"],\n","        \"offset_path\": DEFAULT_OFFSET_PATH\n","    }\n","}\n","\n","\n","def handle_underscores_for_latex(model_name):\n","    return model_name.replace(\"_\", \"\\\\_\")"]},{"cell_type":"markdown","metadata":{"id":"EUexSX71TFuL"},"source":["# Time"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":399,"status":"ok","timestamp":1723654122596,"user":{"displayName":"Kai Ponel","userId":"09877000230544749752"},"user_tz":-120},"id":"aFC140NATJYe"},"outputs":[],"source":["def get_caption_time_one_dim(model_name):\n","    return f\"\\\\tableCaptionTimeOneDim{{{handle_underscores_for_latex(model_name)}}}\"\n","def get_caption_time_avg_one_dim(model_name):\n","    return f\"\\\\tableCaptionTimeAvgOneDim{{{handle_underscores_for_latex(model_name)}}}\"\n","def get_caption_time_relative_one_dim(model_name):\n","    return f\"\\\\tableCaptionTimeRelativeOneDim{{{handle_underscores_for_latex(model_name)}}}\"\n","def get_caption_time_avg_relative_one_dim(model_name):\n","    return f\"\\\\tableCaptionTimeAvgRelativeOneDim{{{handle_underscores_for_latex(model_name)}}}\"\n","\n","def get_all_eval_times(base_path, model_name, dims, quantization_techniques, tasks, offset_path):\n","    scores = []\n","\n","    for technique in quantization_techniques:\n","        for dim in dims:\n","            row = {'Quantization Technique': technique, 'Dimensionality': dim}\n","            total_time = 0\n","            for task in tasks:\n","                subfolder = f\"{model_name}_{dim}_{technique}\"\n","                file_path = os.path.join(base_path, subfolder, offset_path, f\"{task}.json\")\n","\n","                try:\n","                    with open(file_path, 'r') as file:\n","                        data = json.load(file)\n","                        eval_time = data[\"evaluation_time\"]\n","                        row[task] = eval_time\n","                        total_time += eval_time\n","                except (FileNotFoundError, KeyError) as e:\n","                    print(f\"Error reading file {file_path}: {e}\")\n","                    row[task] = None\n","\n","            if 'all' in tasks_dict and tasks == tasks_dict['all']:\n","                row['Total_Time'] = total_time\n","\n","            scores.append(row)\n","\n","    return scores\n","\n","def calculate_averages(df, tasks_dict):\n","    df['Average_All_Tasks'] = df[tasks_dict['all']].mean(axis=1)\n","    for category, tasks in tasks_dict.items():\n","        if category != 'all':  \n","            df[f'Average_{category}'] = df[tasks].mean(axis=1)\n","    return df\n","\n","def generate_pandas_dataframe_eval_times(base_path, model_name, dims, quantization_techniques, tasks, offset_path, tasks_dict):\n","    scores = get_all_eval_times(base_path, model_name, dims, quantization_techniques, tasks, offset_path)\n","    df = pd.DataFrame(scores)  \n","    if 'Total_Time' in df.columns:\n","        df = df.drop(columns=['Total_Time'])\n","    df = df.round(4)\n","    if 'Total_Time' in df.columns:\n","        total_evaluation_time = df['Total_Time'].sum()\n","        print(f\"Total evaluation time needed for the entire model: {total_evaluation_time:.2f} seconds\")\n","    dataframe_to_latex(df=df, test_type=\"Time\", model_name=model_name, precision=2, caption=get_caption_time_one_dim(model_name))\n","    return df\n","\n","\n","def generate_pandas_dataframe_eval_times_average(base_path, model_name, dims, quantization_techniques, tasks, offset_path, tasks_dict):\n","    scores = get_all_eval_times(base_path, model_name, dims, quantization_techniques, tasks, offset_path)\n","    df = pd.DataFrame(scores)\n","    df = calculate_averages(df, tasks_dict)\n","    average_columns = [col for col in df.columns if col.startswith('Average_') or col==\"Total_Time\"]\n","    df_avg_only = df[['Quantization Technique', 'Dimensionality'] + average_columns]\n","    df_avg_only = df_avg_only.round(4)\n","    if 'Total_Time' in df.columns:\n","        total_evaluation_time = df['Total_Time'].sum()\n","        print(f\"Total evaluation time needed for the entire model: {total_evaluation_time:.2f} seconds\")\n","    dataframe_to_latex(df=df_avg_only, test_type=\"TimeAvg\", model_name=model_name, precision=2, caption=get_caption_time_avg_one_dim(model_name))\n","    return df_avg_only\n","\n","def generate_pandas_dataframe_relative_eval_times(base_path, model_name, dims, quantization_techniques, tasks, offset_path, tasks_dict):\n","    scores = get_all_eval_times(base_path, model_name, dims, quantization_techniques, tasks, offset_path)\n","    df = pd.DataFrame(scores)\n","    max_dim = max(dims)\n","    baseline_filter = (df['Dimensionality'] == max_dim) & (df['Quantization Technique'] == 'float32')\n","    baseline_df = df[baseline_filter]\n","    baseline_times = {}\n","    for task in tasks:\n","        baseline_times[task] = baseline_df[task].values[0] if task in baseline_df.columns else None    \n","    for task in tasks:\n","        if task in df.columns:\n","            df[f'Relative_{task}'] = df[task] / baseline_times[task]\n","    relative_columns = [col for col in df.columns if col.startswith('Relative_')]\n","    df_relative_times = df[['Quantization Technique', 'Dimensionality'] + relative_columns]\n","    df_relative_times = df_relative_times.round(4)\n","    dataframe_to_latex(df=df_relative_times, test_type=\"RelativeTime\", model_name=model_name, precision=3, caption=get_caption_time_relative_one_dim(model_name), replace_relative=True)\n","    return df_relative_times\n","\n","def generate_pandas_dataframe_eval_times_average_relative(base_path, model_name, dims, quantization_techniques, tasks, offset_path, tasks_dict):\n","    df_relative_times = generate_pandas_dataframe_relative_eval_times(base_path, model_name, dims, quantization_techniques, tasks, offset_path, tasks_dict)\n","    average_columns = {}\n","    for category, task_list in tasks_dict.items():\n","        relative_task_columns = [f'Relative_{task}' for task in task_list if f'Relative_{task}' in df_relative_times.columns]\n","        if relative_task_columns:\n","            df_relative_times[f'Average_Relative_{category}'] = df_relative_times[relative_task_columns].mean(axis=1)\n","            average_columns[f'Average_Relative_{category}'] = df_relative_times[f'Average_Relative_{category}']\n","    df_avg_relative_only = df_relative_times[['Quantization Technique', 'Dimensionality'] + list(average_columns.keys())]\n","    df_avg_relative_only = df_avg_relative_only.round(4)\n","    dataframe_to_latex(df=df_avg_relative_only, test_type=\"AverageRelativeTime\", model_name=model_name, precision=3, caption=get_caption_time_avg_relative_one_dim(model_name))\n","    return df_avg_relative_only\n","\n"]},{"cell_type":"markdown","metadata":{"id":"DXu5uuRobw7R"},"source":["## Stella en_400M_v5"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1723654122596,"user":{"displayName":"Kai Ponel","userId":"09877000230544749752"},"user_tz":-120},"id":"9mMl4OShbw7W"},"outputs":[],"source":["MODEL_NAME = \"stella_en_400M_v5\"\n","MODEL_OFFSET_PATH = models_dict[MODEL_NAME][\"offset_path\"]\n","MODEL_BASE_PATH = models_dict[MODEL_NAME][\"path\"]\n","dims = models_dict[MODEL_NAME][\"dims\"]\n","quantization_techniques = models_dict[MODEL_NAME][\"quantization_techniques\"]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":283074,"status":"ok","timestamp":1723654405668,"user":{"displayName":"Kai Ponel","userId":"09877000230544749752"},"user_tz":-120},"id":"GgACVnKtbw7W","outputId":"e72debaf-4569-44d7-8a9d-02031695cf62"},"outputs":[],"source":["df_time_stella = generate_pandas_dataframe_eval_times(MODEL_BASE_PATH, MODEL_NAME, dims, quantization_techniques, tasks_dict[\"all\"], MODEL_OFFSET_PATH, tasks_dict)\n","display(df_time_stella)"]},{"cell_type":"markdown","metadata":{"id":"I4ZNkL-Xy4yD"},"source":["### Average"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":3365,"status":"ok","timestamp":1723654409024,"user":{"displayName":"Kai Ponel","userId":"09877000230544749752"},"user_tz":-120},"id":"KSRVH53Uy8mj","outputId":"4372165c-a36e-43e3-c2c9-c3537c0e384e"},"outputs":[],"source":["df_time_stella_avg = generate_pandas_dataframe_eval_times_average(MODEL_BASE_PATH, MODEL_NAME, dims, quantization_techniques, tasks_dict[\"all\"], MODEL_OFFSET_PATH, tasks_dict)\n","display(df_time_stella_avg)"]},{"cell_type":"markdown","metadata":{"id":"4l-ggqZ__ruW"},"source":["### Relative"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":3705,"status":"ok","timestamp":1723654412720,"user":{"displayName":"Kai Ponel","userId":"09877000230544749752"},"user_tz":-120},"id":"tqUFY4sJ_ssM","outputId":"8332f765-1722-47a9-9602-8082a565e51a"},"outputs":[],"source":["df_relative_time_stella = generate_pandas_dataframe_relative_eval_times(MODEL_BASE_PATH, MODEL_NAME, dims, quantization_techniques, tasks_dict[\"all\"], MODEL_OFFSET_PATH, tasks_dict)\n","display(df_relative_time_stella)"]},{"cell_type":"markdown","metadata":{"id":"P-seXKIEANNy"},"source":["### Average Relative"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":3699,"status":"ok","timestamp":1723654416417,"user":{"displayName":"Kai Ponel","userId":"09877000230544749752"},"user_tz":-120},"id":"wn_75teFAOpx","outputId":"cf68b81b-6516-45fa-f004-32e74a4ab1cf"},"outputs":[],"source":["df_avg_relative_time_stella = generate_pandas_dataframe_eval_times_average_relative(MODEL_BASE_PATH, MODEL_NAME, dims, quantization_techniques, tasks_dict[\"all\"], MODEL_OFFSET_PATH, tasks_dict)\n","display(df_avg_relative_time_stella)"]},{"cell_type":"markdown","metadata":{"id":"1BmkFZ2Jbw7X"},"source":["## MixedBread-AI V1"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1723654416418,"user":{"displayName":"Kai Ponel","userId":"09877000230544749752"},"user_tz":-120},"id":"vDS6Sn1ibw7X"},"outputs":[],"source":["MODEL_NAME = \"mxbai-embed-large-v1\"\n","MODEL_OFFSET_PATH = models_dict[MODEL_NAME][\"offset_path\"]\n","MODEL_BASE_PATH = models_dict[MODEL_NAME][\"path\"]\n","dims = models_dict[MODEL_NAME][\"dims\"]\n","quantization_techniques = models_dict[MODEL_NAME][\"quantization_techniques\"]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":279284,"status":"ok","timestamp":1723654695692,"user":{"displayName":"Kai Ponel","userId":"09877000230544749752"},"user_tz":-120},"id":"v3kQ-wGObw7X","outputId":"bd634452-a635-4934-8f82-3cd6f273b022"},"outputs":[],"source":["df_time_mbai = generate_pandas_dataframe_eval_times(MODEL_BASE_PATH, MODEL_NAME, dims, quantization_techniques, tasks_dict[\"all\"], MODEL_OFFSET_PATH, tasks_dict)\n","display(df_time_mbai)"]},{"cell_type":"markdown","metadata":{"id":"enRpOgVDzAcL"},"source":["### Average"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":3335,"status":"ok","timestamp":1723654699012,"user":{"displayName":"Kai Ponel","userId":"09877000230544749752"},"user_tz":-120},"id":"DNHpYDogzBVF","outputId":"d2b9bb0e-cb86-4c02-ae07-e8b3ead96721"},"outputs":[],"source":["df_time_mbai_avg = generate_pandas_dataframe_eval_times_average(MODEL_BASE_PATH, MODEL_NAME, dims, quantization_techniques, tasks_dict[\"all\"], MODEL_OFFSET_PATH, tasks_dict)\n","display(df_time_mbai_avg)"]},{"cell_type":"markdown","metadata":{"id":"ndcimbnSGJ4x"},"source":["### Relative"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":3617,"status":"ok","timestamp":1723654702627,"user":{"displayName":"Kai Ponel","userId":"09877000230544749752"},"user_tz":-120},"id":"1XGv9bJtGJ4y","outputId":"d9aee62e-d9c9-46d3-8d66-e2042cd07781"},"outputs":[],"source":["df_relative_time_mbai = generate_pandas_dataframe_relative_eval_times(MODEL_BASE_PATH, MODEL_NAME, dims, quantization_techniques, tasks_dict[\"all\"], MODEL_OFFSET_PATH, tasks_dict)\n","display(df_relative_time_mbai)"]},{"cell_type":"markdown","metadata":{"id":"bU4bUQwXGJ4y"},"source":["### Average Relative"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":3464,"status":"ok","timestamp":1723654706081,"user":{"displayName":"Kai Ponel","userId":"09877000230544749752"},"user_tz":-120},"id":"LeGqJD56GJ4y","outputId":"d69232c9-8aa0-4d47-8160-2a0805fd6ac2"},"outputs":[],"source":["df_avg_relative_time_mbai = generate_pandas_dataframe_eval_times_average_relative(MODEL_BASE_PATH, MODEL_NAME, dims, quantization_techniques, tasks_dict[\"all\"], MODEL_OFFSET_PATH, tasks_dict)\n","display(df_avg_relative_time_mbai)"]},{"cell_type":"markdown","metadata":{"id":"0DiRPmvCbw7X"},"source":["## Nomic-text-embed-v1.5"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1723654706081,"user":{"displayName":"Kai Ponel","userId":"09877000230544749752"},"user_tz":-120},"id":"aEPPPj5ubw7X"},"outputs":[],"source":["MODEL_NAME = \"nomic-embed-text-v1.5\" #\"mxbai-embed-large-v1\"\n","MODEL_BASE_PATH = models_dict[MODEL_NAME][\"path\"]\n","MODEL_OFFSET_PATH = models_dict[MODEL_NAME][\"offset_path\"]\n","dims = models_dict[MODEL_NAME][\"dims\"]\n","quantization_techniques = models_dict[MODEL_NAME][\"quantization_techniques\"]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":16080,"status":"ok","timestamp":1723654971311,"user":{"displayName":"Kai Ponel","userId":"09877000230544749752"},"user_tz":-120},"id":"Ni4AFJXVbw7X"},"outputs":[],"source":["df_time_nomic = generate_pandas_dataframe_eval_times(MODEL_BASE_PATH, MODEL_NAME, dims, quantization_techniques, tasks_dict[\"all\"], MODEL_OFFSET_PATH, tasks_dict)\n","display(df_time_nomic)"]},{"cell_type":"markdown","metadata":{"id":"4B01cZUlzEmq"},"source":["### Average"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":3377,"status":"ok","timestamp":1723654974685,"user":{"displayName":"Kai Ponel","userId":"09877000230544749752"},"user_tz":-120},"id":"ktGMhOeBzFZa"},"outputs":[],"source":["df_time_nomic_avg = generate_pandas_dataframe_eval_times_average(MODEL_BASE_PATH, MODEL_NAME, dims, quantization_techniques, tasks_dict[\"all\"], MODEL_OFFSET_PATH, tasks_dict)\n","display(df_time_nomic_avg)"]},{"cell_type":"markdown","metadata":{"id":"-79k3_wEGPoq"},"source":["### Relative"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":3847,"status":"ok","timestamp":1723654978531,"user":{"displayName":"Kai Ponel","userId":"09877000230544749752"},"user_tz":-120},"id":"FRt8znjzGPow"},"outputs":[],"source":["df_relative_time_nomic = generate_pandas_dataframe_relative_eval_times(MODEL_BASE_PATH, MODEL_NAME, dims, quantization_techniques, tasks_dict[\"all\"], MODEL_OFFSET_PATH, tasks_dict)\n","display(df_relative_time_nomic)"]},{"cell_type":"markdown","metadata":{"id":"Tzy-vg_KGPox"},"source":["### Average Relative"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"kDp3htpXGPox"},"outputs":[],"source":["df_avg_relative_time_nomic = generate_pandas_dataframe_eval_times_average_relative(MODEL_BASE_PATH, MODEL_NAME, dims, quantization_techniques, tasks_dict[\"all\"], MODEL_OFFSET_PATH, tasks_dict)\n","display(df_avg_relative_time_nomic)"]},{"cell_type":"markdown","metadata":{"id":"uehX66hGndS2"},"source":["# Accuracy Compute TradeOff"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"5M8KDdkMnnGa"},"outputs":[],"source":["def get_caption_memory_one_dim(model_name):\n","    return f\"\\\\tableCaptionMemoryOneDim{{{handle_underscores_for_latex(model_name)}}}\"\n","def get_caption_memory_avg_one_dim(model_name):\n","    return f\"\\\\tableCaptionMemoryAvgOneDim{{{handle_underscores_for_latex(model_name)}}}\"\n","def get_caption_memory_relative_one_dim(model_name):\n","    return f\"\\\\tableCaptionMemoryRelativeOneDim{{{handle_underscores_for_latex(model_name)}}}\"\n","def get_caption_memory_avg_relative_one_dim(model_name):\n","    return f\"\\\\tableCaptionMemoryAvgRelativeOneDim{{{handle_underscores_for_latex(model_name)}}}\"\n","\n","def get_all_scores_accuracy_compute(base_path, model_name, dims, quantization_techniques, tasks, offset_path):\n","    scores = []\n","\n","    for technique in quantization_techniques:\n","        for dim in dims:\n","            row = {\n","                'Quantization Technique': technique,\n","                'Dimensionality': dim,\n","                'Memory Used (bits)': calculate_memory_used(dim, technique)\n","            }\n","            for task in tasks:\n","                subfolder = f\"{model_name}_{dim}_{technique}\"\n","                file_path = os.path.join(base_path, subfolder, offset_path, f\"{task}.json\")\n","                try:\n","                    with open(file_path, 'r') as file:\n","                        data = json.load(file)\n","                        main_score = data[\"scores\"][\"test\"][0][\"main_score\"]\n","                        row[task] = main_score\n","                except (FileNotFoundError, KeyError) as e:\n","                    print(f\"Error reading file {file_path}: {e}\")\n","                    row[task] = None\n","\n","            scores.append(row)\n","\n","    return scores\n","\n","def calculate_memory_used(embedding_size, quantization_method):\n","    if quantization_method == 'float32':\n","        return embedding_size * 32\n","    elif quantization_method == 'int8':\n","        return embedding_size * 8\n","    elif quantization_method == 'binary':\n","        return embedding_size * 1\n","    else:\n","        raise ValueError(f\"Unknown quantization method: {quantization_method}\")\n","\n","def calculate_averages(df, tasks_dict):\n","    df['Average_All_Tasks'] = df[tasks_dict['all']].mean(axis=1)\n","    return df\n","\n","def calculate_tradeoff_metrics(df):\n","    df['MAP'] = df['Memory Used (bits)'] * (1 - df['Average_All_Tasks'])\n","    max_memory = df['Memory Used (bits)'].max()\n","    df['NMAT_Average'] = df['Memory Used (bits)'] / max_memory + (1 - df['Average_All_Tasks'])\n","    return df\n","\n","def generate_pandas_dataframe_accuracy_compute(base_path, model_name, dims, quantization_techniques, tasks, offset_path, tasks_dict):\n","    scores = get_all_scores_accuracy_compute(base_path, model_name, dims, quantization_techniques, tasks, offset_path)\n","    df = pd.DataFrame(scores)\n","    df = df.round(4)\n","    dataframe_to_latex(df=df, test_type=\"Memory\", model_name=model_name, precision=3, caption=get_caption_memory_one_dim(model_name))\n","    return df\n","\n","\n","def get_all_scores_accuracy_compute_averages(base_path, model_name, dims, quantization_techniques, tasks, offset_path, tasks_dict):\n","    scores = []\n","    for technique in quantization_techniques:\n","        for dim in dims:\n","            row = {\n","                'Quantization Technique': technique,\n","                'Dimensionality': dim,\n","                'Memory Used (bits)': calculate_memory_used(dim, technique)\n","            }\n","            task_category_averages = {category: [] for category in tasks_dict}\n","            all_task_scores = []\n","            for task in tasks:\n","                subfolder = f\"{model_name}_{dim}_{technique}\"\n","                file_path = os.path.join(base_path, subfolder, offset_path, f\"{task}.json\")\n","                try:\n","                    with open(file_path, 'r') as file:\n","                        data = json.load(file)\n","                        main_score = data[\"scores\"][\"test\"][0][\"main_score\"]\n","                        all_task_scores.append(main_score)\n","                        for category, task_list in tasks_dict.items():\n","                            if task in task_list:\n","                                task_category_averages[category].append(main_score)\n","                except (FileNotFoundError, KeyError) as e:\n","                    print(f\"Error reading file {file_path}: {e}\")\n","            for category, scores_list in task_category_averages.items():\n","                if scores_list:\n","                    row[f'Average_{category}'] = sum(scores_list) / len(scores_list)\n","                else:\n","                    row[f'Average_{category}'] = None\n","            scores.append(row)\n","    return scores\n","\n","def generate_pandas_dataframe_accuracy_compute_averages(base_path, model_name, dims, quantization_techniques, tasks, offset_path, tasks_dict):\n","    scores = get_all_scores_accuracy_compute_averages(base_path, model_name, dims, quantization_techniques, tasks, offset_path, tasks_dict)\n","    df = pd.DataFrame(scores)\n","    df = df.round(4)\n","    dataframe_to_latex(df=df, test_type=\"MemoryAvg\", model_name=model_name, precision=3, caption=get_caption_memory_avg_one_dim(model_name))\n","    return df\n","\n","\n","def generate_pandas_dataframe_relative_scores(base_path, model_name, dims, quantization_techniques, tasks, offset_path, tasks_dict):\n","    scores = get_all_scores_accuracy_compute(base_path, model_name, dims, quantization_techniques, tasks, offset_path)\n","    df = pd.DataFrame(scores)\n","    max_dim = max(dims)\n","    baseline_filter = (df['Dimensionality'] == max_dim) & (df['Quantization Technique'] == 'float32')\n","    baseline_df = df[baseline_filter]\n","    baseline_scores = {}\n","    for task in tasks:\n","        baseline_scores[task] = baseline_df[task].values[0] if task in baseline_df.columns else None\n","    for task in tasks:\n","        if task in df.columns:\n","            df[f'Relative_{task}'] = df[task] / baseline_scores[task]\n","    relative_columns = [col for col in df.columns if col.startswith('Relative_')]\n","    df_relative_scores = df[['Quantization Technique', 'Dimensionality', 'Memory Used (bits)'] + relative_columns]\n","    df_relative_scores = df_relative_scores.round(4)\n","    dataframe_to_latex(df=df_relative_scores, test_type=\"RelativeScores\", model_name=model_name, precision=3, caption=get_caption_memory_relative_one_dim(model_name), replace_relative=True)\n","    return df_relative_scores\n","\n","\n","def generate_pandas_dataframe_scores_average_relative(base_path, model_name, dims, quantization_techniques, tasks, offset_path, tasks_dict):\n","    df_relative_scores = generate_pandas_dataframe_relative_scores(base_path, model_name, dims, quantization_techniques, tasks, offset_path, tasks_dict)\n","    for category, task_list in tasks_dict.items():\n","        relative_task_columns = [f'Relative_{task}' for task in task_list if f'Relative_{task}' in df_relative_scores.columns]\n","        if relative_task_columns:\n","            df_relative_scores[f'Average_Relative_{category}'] = df_relative_scores[relative_task_columns].mean(axis=1)\n","    average_columns = [col for col in df_relative_scores.columns if col.startswith('Average_Relative_')]\n","    df_avg_relative_only = df_relative_scores[['Quantization Technique', 'Dimensionality', 'Memory Used (bits)'] + average_columns]\n","    df_avg_relative_only = df_avg_relative_only.round(4)\n","    dataframe_to_latex(df=df_avg_relative_only, test_type=\"AverageRelativeScores\", model_name=model_name, precision=3, caption=get_caption_memory_avg_relative_one_dim(model_name))\n","    return df_avg_relative_only"]},{"cell_type":"markdown","metadata":{"id":"XSSGGjk856Y6"},"source":["##  Stella en_400M_v5"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"bUjI32UE56Y_"},"outputs":[],"source":["MODEL_NAME = \"stella_en_400M_v5\"\n","MODEL_OFFSET_PATH = models_dict[MODEL_NAME][\"offset_path\"]\n","MODEL_BASE_PATH = models_dict[MODEL_NAME][\"path\"]\n","dims = models_dict[MODEL_NAME][\"dims\"]\n","quantization_techniques = models_dict[MODEL_NAME][\"quantization_techniques\"]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"rAuQC5hS56Y_"},"outputs":[],"source":["df_mem_stella = generate_pandas_dataframe_accuracy_compute(MODEL_BASE_PATH, MODEL_NAME, dims, quantization_techniques, tasks_dict[\"all\"], MODEL_OFFSET_PATH, tasks_dict)\n","display(df_mem_stella)"]},{"cell_type":"markdown","metadata":{"id":"ZYMOhHVkF0Wg"},"source":["### Average"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"_bodKa507WW8"},"outputs":[],"source":["df_mem_stella_avg = generate_pandas_dataframe_accuracy_compute_averages(MODEL_BASE_PATH, MODEL_NAME, dims, quantization_techniques, tasks_dict[\"all\"], MODEL_OFFSET_PATH, tasks_dict)\n","display(df_mem_stella_avg)"]},{"cell_type":"markdown","metadata":{"id":"Vnyqr7FLBoew"},"source":["### Relative"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"PymvsFcxBpye"},"outputs":[],"source":["df_relative_scores_stella = generate_pandas_dataframe_relative_scores(MODEL_BASE_PATH, MODEL_NAME, dims, quantization_techniques, tasks_dict[\"all\"], MODEL_OFFSET_PATH, tasks_dict)\n","display(df_relative_scores_stella)"]},{"cell_type":"markdown","metadata":{"id":"3gTXVlCBBsIJ"},"source":["### Average Relative"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"2iBUZcl4Bwg-"},"outputs":[],"source":["df_avg_relative_scores_stella = generate_pandas_dataframe_scores_average_relative(MODEL_BASE_PATH, MODEL_NAME, dims, quantization_techniques, tasks_dict[\"all\"], MODEL_OFFSET_PATH, tasks_dict)\n","display(df_avg_relative_scores_stella)"]},{"cell_type":"markdown","metadata":{"id":"0ObuTrVX5uqo"},"source":["## Mixed-Bread-Ai v1"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"zwvuo2oyn5FZ"},"outputs":[],"source":["MODEL_NAME = \"mxbai-embed-large-v1\"\n","MODEL_OFFSET_PATH = models_dict[MODEL_NAME][\"offset_path\"]\n","MODEL_BASE_PATH = models_dict[MODEL_NAME][\"path\"]\n","dims = models_dict[MODEL_NAME][\"dims\"]\n","quantization_techniques = models_dict[MODEL_NAME][\"quantization_techniques\"]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"cdR3mRvtnq9s"},"outputs":[],"source":["df_mem_mbai = generate_pandas_dataframe_accuracy_compute(MODEL_BASE_PATH, MODEL_NAME, dims, quantization_techniques, tasks_dict[\"all\"], MODEL_OFFSET_PATH, tasks_dict)\n","display(df_mem_mbai)"]},{"cell_type":"markdown","metadata":{"id":"gXUEfiwbF11Y"},"source":["### Average"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"i6mYel_T7bLi"},"outputs":[],"source":["df_mem_mbai_avg = generate_pandas_dataframe_accuracy_compute_averages(MODEL_BASE_PATH, MODEL_NAME, dims, quantization_techniques, tasks_dict[\"all\"], MODEL_OFFSET_PATH, tasks_dict)\n","display(df_mem_mbai_avg)"]},{"cell_type":"markdown","metadata":{"id":"2T0meQpVGXX-"},"source":["### Relative"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"jEVa7NaRGXX_"},"outputs":[],"source":["df_relative_scores_mbai = generate_pandas_dataframe_relative_scores(MODEL_BASE_PATH, MODEL_NAME, dims, quantization_techniques, tasks_dict[\"all\"], MODEL_OFFSET_PATH, tasks_dict)\n","display(df_relative_scores_mbai)"]},{"cell_type":"markdown","metadata":{"id":"ZgQ5Q7s_GXX_"},"source":["### Average Relative"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"MgSuahkOGXX_"},"outputs":[],"source":["df_avg_relative_scores_mbai = generate_pandas_dataframe_scores_average_relative(MODEL_BASE_PATH, MODEL_NAME, dims, quantization_techniques, tasks_dict[\"all\"], MODEL_OFFSET_PATH, tasks_dict)\n","display(df_avg_relative_scores_mbai)"]},{"cell_type":"markdown","metadata":{"id":"4IbU5xfz50Ll"},"source":["## Nomic-text-embed-v1.5"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"M2tEyQ5x50Lr"},"outputs":[],"source":["MODEL_NAME = \"nomic-embed-text-v1.5\"\n","MODEL_BASE_PATH = models_dict[MODEL_NAME][\"path\"]\n","MODEL_OFFSET_PATH = models_dict[MODEL_NAME][\"offset_path\"]\n","dims = models_dict[MODEL_NAME][\"dims\"]\n","quantization_techniques = models_dict[MODEL_NAME][\"quantization_techniques\"]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"JiQ5vntd50Lr"},"outputs":[],"source":["df_mem_nomic = generate_pandas_dataframe_accuracy_compute(MODEL_BASE_PATH, MODEL_NAME, dims, quantization_techniques, tasks_dict[\"all\"], MODEL_OFFSET_PATH, tasks_dict)\n","display(df_mem_nomic)"]},{"cell_type":"markdown","metadata":{"id":"RzU-OdV7F4Aj"},"source":["### Average"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"Hzn-CsVHjiPT"},"outputs":[],"source":["df_mem_nomic_avg = generate_pandas_dataframe_accuracy_compute_averages(MODEL_BASE_PATH, MODEL_NAME, dims, quantization_techniques, tasks_dict[\"all\"], MODEL_OFFSET_PATH, tasks_dict)\n","display(df_mem_nomic_avg)"]},{"cell_type":"markdown","metadata":{"id":"XSfj7vOIGlbt"},"source":["### Relative"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"960IMZk0Glby"},"outputs":[],"source":["df_relative_scores_nomic = generate_pandas_dataframe_relative_scores(MODEL_BASE_PATH, MODEL_NAME, dims, quantization_techniques, tasks_dict[\"all\"], MODEL_OFFSET_PATH, tasks_dict)\n","display(df_relative_scores_nomic)"]},{"cell_type":"markdown","metadata":{"id":"KPKbo7GzGlby"},"source":["### Average Relative"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"AtvcMUuBGlby"},"outputs":[],"source":["df_avg_relative_scores_nomic = generate_pandas_dataframe_scores_average_relative(MODEL_BASE_PATH, MODEL_NAME, dims, quantization_techniques, tasks_dict[\"all\"], MODEL_OFFSET_PATH, tasks_dict)\n","display(df_avg_relative_scores_nomic)"]},{"cell_type":"markdown","metadata":{"id":"j9yCP2Wi4dA0"},"source":["# 2D MixedBread Model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"zve4WHu34w2p"},"outputs":[],"source":["MODEL_NAME = \"mxbai-embed-2d-large-v1\"\n","MODEL_OFFSET_PATH = DEFAULT_OFFSET_PATH\n","MODEL_BASE_PATH = f\"{BASE_PATH}/2D/mixedbread-ai\"\n","dims = [1024, 512, 256, 128, 64, 32, 16, 8]\n","quantization_techniques = [\"float32\", \"int8\", \"binary\"]\n","INFERENCE_LAYERS = [24, 20, 16, 12]"]},{"cell_type":"markdown","metadata":{"id":"Kr20hXre4w2q"},"source":["## Time"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"rQI2DxlP4w2q"},"outputs":[],"source":["def get_caption_time_two_dim(model_name, quantization_technique):\n","    return f\"\\\\tableCaptionTimeTwoDim{{{model_name}}}{{{quantization_technique}}}\"\n","def get_caption_time_avg_two_dim(model_name):\n","    return f\"\\\\tableCaptionTimeAvgTwoDim{{{model_name}}}\"\n","def get_caption_time_relative_two_dim(model_name, quantization_techniques):\n","    return f\"\\\\tableCaptionTimeRelativeTwoDim{{{model_name}}}{{{quantization_techniques}}}\"\n","def get_caption_time_avg_relative_two_dim(model_name):\n","    return f\"\\\\tableCaptionTimeAvgRelativeTwoDim{{{model_name}}}\"\n","\n","\n","\n","def get_all_eval_times(base_path, model_name, dims, quantization_techniques, tasks, inference_layers, offset_path):\n","    scores = []\n","    for technique in quantization_techniques:\n","        for dim in dims:\n","            for layer in inference_layers:\n","                row = {'Quantization Technique': technique, 'Dimensionality': dim, 'Inference Layer': layer}\n","                total_time = 0\n","                for task in tasks:\n","                    subfolder = f\"{model_name}_{dim}_{technique}_{layer}\"\n","                    file_path = os.path.join(base_path, subfolder, offset_path, f\"{task}.json\")\n","\n","                    try:\n","                        with open(file_path, 'r') as file:\n","                            data = json.load(file)\n","                            eval_time = data[\"evaluation_time\"]\n","                            row[task] = eval_time\n","                            total_time += eval_time\n","                    except (FileNotFoundError, KeyError) as e:\n","                        print(f\"Error reading file {file_path}: {e}\")\n","                        row[task] = None\n","                if 'all' in tasks_dict and tasks == tasks_dict['all']:\n","                    row['Total_Time'] = total_time\n","                scores.append(row)\n","    return scores\n","\n","def generate_pandas_dataframe_eval_times(base_path, model_name, dims, quantization_techniques, tasks, inference_layers, offset_path, tasks_dict):\n","    scores = get_all_eval_times(base_path, model_name, dims, quantization_techniques, tasks, inference_layers, offset_path)  \n","    df = pd.DataFrame(scores)\n","    df = df.round(2)\n","    if 'Total_Time' in df.columns:\n","        total_evaluation_time = df['Total_Time'].sum()\n","        print(f\"Total evaluation time needed for the entire model: {total_evaluation_time:.2f} seconds\")\n","        df = df.drop(columns=['Total_Time'])\n","    df_float32 = df[df['Quantization Technique'] == 'float32']\n","    df_int8 = df[df['Quantization Technique'] == 'int8']\n","    df_binary = df[df['Quantization Technique'] == 'binary']\n","    dataframe_to_latex(df=df_float32, test_type=\"Time\", model_name=model_name, precision=2, caption=get_caption_time_two_dim(model_name, \"float\"), custom_name=\"float\")\n","    dataframe_to_latex(df=df_int8, test_type=\"Time\", model_name=model_name, precision=2, caption=get_caption_time_two_dim(model_name, \"int\"), custom_name=\"int\")\n","    dataframe_to_latex(df=df_binary, test_type=\"Time\", model_name=model_name, precision=2, caption=get_caption_time_two_dim(model_name, \"binary\"), custom_name=\"binary\")\n","    return df\n","\n","\n","def calculate_averages(df, tasks_dict):\n","    df['Average_All_Tasks'] = df[tasks_dict['all']].mean(axis=1)\n","    for category, tasks in tasks_dict.items():\n","        if category != 'all':  \n","            df[f'Average_{category}'] = df[tasks].mean(axis=1)\n","    return df\n","\n","def generate_pandas_dataframe_eval_times_average(base_path, model_name, dims, quantization_techniques, tasks, inference_layers, offset_path, tasks_dict):\n","    scores = get_all_eval_times(base_path, model_name, dims, quantization_techniques, tasks, inference_layers, offset_path)\n","    df = pd.DataFrame(scores)\n","    df = df.round(2)\n","    df = calculate_averages(df, tasks_dict)\n","    average_columns = [col for col in df.columns if col.startswith('Average_')]\n","    df_avg_only = df[['Quantization Technique', 'Dimensionality', 'Inference Layer'] + average_columns]\n","    if 'Total_Time' in df.columns:\n","        total_evaluation_time = df['Total_Time'].sum()\n","        print(f\"Total evaluation time needed for the entire model: {total_evaluation_time:.2f} seconds\")\n","    dataframe_to_latex(df=df_avg_only, test_type=\"TimeAvg\", model_name=model_name, precision=2, caption=get_caption_time_avg_two_dim(model_name))\n","    return df_avg_only\n","\n","def generate_pandas_dataframe_relative_eval_times(base_path, model_name, dims, quantization_techniques, tasks, inference_layers, offset_path, tasks_dict):\n","    scores = get_all_eval_times(base_path, model_name, dims, quantization_techniques, tasks, inference_layers, offset_path)\n","    df = pd.DataFrame(scores)\n","    max_dim = max(dims)\n","    last_layer = inference_layers[0]  \n","    baseline_filter = (df['Dimensionality'] == max_dim) & (df['Quantization Technique'] == 'float32') & (df['Inference Layer'] == last_layer)\n","    baseline_df = df[baseline_filter]\n","    baseline_times = {}\n","    for task in tasks:\n","        baseline_times[task] = baseline_df[task].values[0] if task in baseline_df.columns else None\n","    for task in tasks:\n","        if task in df.columns:\n","            df[f'Relative_{task}'] = df[task] / baseline_times[task]\n","    relative_columns = [col for col in df.columns if col.startswith('Relative_')]\n","    df_relative_times = df[['Quantization Technique', 'Dimensionality', 'Inference Layer'] + relative_columns]\n","    df_relative_times = df_relative_times.round(4)\n","    df_float32 = df_relative_times[df_relative_times['Quantization Technique'] == 'float32']\n","    df_int8 = df_relative_times[df_relative_times['Quantization Technique'] == 'int8']\n","    df_binary = df_relative_times[df_relative_times['Quantization Technique'] == 'binary']\n","    dataframe_to_latex(df=df_float32, test_type=\"RelativeTime\", model_name=model_name, precision=3, caption=get_caption_time_relative_two_dim(model_name, \"float\"), custom_name=\"float\", replace_relative=True)\n","    dataframe_to_latex(df=df_int8, test_type=\"RelativeTime\", model_name=model_name, precision=3, caption=get_caption_time_relative_two_dim(model_name, \"int\"), custom_name=\"int\", replace_relative=True)\n","    dataframe_to_latex(df=df_binary, test_type=\"RelativeTime\", model_name=model_name, precision=3, caption=get_caption_time_relative_two_dim(model_name, \"binary\"), custom_name=\"binary\", replace_relative=True)\n","    return df_relative_times\n","\n","def generate_pandas_dataframe_eval_times_average_relative(base_path, model_name, dims, quantization_techniques, tasks, inference_layers, offset_path, tasks_dict):\n","    df_relative_times = generate_pandas_dataframe_relative_eval_times(base_path, model_name, dims, quantization_techniques, tasks, inference_layers, offset_path, tasks_dict)\n","    for category, task_list in tasks_dict.items():\n","        relative_task_columns = [f'Relative_{task}' for task in task_list if f'Relative_{task}' in df_relative_times.columns]\n","        if relative_task_columns:\n","            df_relative_times[f'Average_Relative_{category}'] = df_relative_times[relative_task_columns].mean(axis=1)\n","    average_columns = [col for col in df_relative_times.columns if col.startswith('Average_Relative_')]\n","    df_avg_relative_only = df_relative_times[['Quantization Technique', 'Dimensionality', 'Inference Layer'] + average_columns]\n","    df_avg_relative_only = df_avg_relative_only.round(4)\n","    dataframe_to_latex(df=df_avg_relative_only, test_type=\"AverageRelativeTime\", model_name=model_name, precision=3, caption=get_caption_time_avg_relative_two_dim(model_name))\n","    return df_avg_relative_only"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"i5PXxU184w2q"},"outputs":[],"source":["df_time_mbaii = generate_pandas_dataframe_eval_times(MODEL_BASE_PATH, MODEL_NAME, dims, quantization_techniques, tasks_dict[\"all\"], INFERENCE_LAYERS, MODEL_OFFSET_PATH, tasks_dict)\n","display(df_time_mbaii)"]},{"cell_type":"markdown","metadata":{"id":"FSY5WN3NxyZW"},"source":["### Average"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"ngsDrvxpyJpa"},"outputs":[],"source":["df_time_mbaii_avg = generate_pandas_dataframe_eval_times_average(MODEL_BASE_PATH, MODEL_NAME, dims, quantization_techniques, tasks_dict[\"all\"], INFERENCE_LAYERS, MODEL_OFFSET_PATH, tasks_dict)\n","display(df_time_mbaii_avg)"]},{"cell_type":"markdown","metadata":{"id":"OXvff47hCxu1"},"source":["### Relative"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"FMWDat6YCy_i"},"outputs":[],"source":["df_relative_eval_times_stella = generate_pandas_dataframe_relative_eval_times(MODEL_BASE_PATH, MODEL_NAME, dims, quantization_techniques, tasks_dict[\"all\"], INFERENCE_LAYERS, MODEL_OFFSET_PATH, tasks_dict)\n","display(df_relative_eval_times_stella)"]},{"cell_type":"markdown","metadata":{"id":"1aole9-lCzMz"},"source":["### Average Relative"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"7ybsZVQJC330"},"outputs":[],"source":["df_avg_relative_eval_times_stella = generate_pandas_dataframe_eval_times_average_relative(MODEL_BASE_PATH, MODEL_NAME, dims, quantization_techniques, tasks_dict[\"all\"], INFERENCE_LAYERS, MODEL_OFFSET_PATH, tasks_dict)\n","display(df_avg_relative_eval_times_stella)"]},{"cell_type":"markdown","metadata":{"id":"aC5XEgeo4w2q"},"source":["## Accuracy Compute TradeOff"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"YHDHjgc54w2q"},"outputs":[],"source":["def get_caption_memory_two_dim(model_name, quantization_technique):\n","    return f\"\\\\tableCaptionMemoryTwoDim{{{model_name}}}{{{quantization_technique}}}\"\n","def get_caption_memory_avg_two_dim(model_name):\n","    return f\"\\\\tableCaptionMemoryAvgTwoDim{{{model_name}}}\"\n","def get_caption_memory_relative_two_dim(model_name, quantization_technique):\n","    return f\"\\\\tableCaptionMemoryRelativeTwoDim{{{model_name}}}{{{quantization_technique}}}\"\n","def get_caption_memory_avg_relative_two_dim(model_name):\n","    return f\"\\\\tableCaptionMemoryAvgRelativeTwoDim{{{model_name}}}\"\n","\n","def get_all_scores_accuracy_compute(base_path, model_name, dims, quantization_techniques, tasks, inference_layers, offset_path):\n","    scores = []\n","    for technique in quantization_techniques:\n","        for dim in dims:\n","            for layer in inference_layers:\n","                row = {\n","                    'Quantization Technique': technique,\n","                    'Dimensionality': dim,\n","                    'Inference Layer': layer,\n","                    'Memory Used (bits)': calculate_memory_used(dim, technique)\n","                }\n","                for task in tasks:\n","                    subfolder = f\"{model_name}_{dim}_{technique}_{layer}\"\n","                    file_path = os.path.join(base_path, subfolder, offset_path, f\"{task}.json\")\n","                    try:\n","                        with open(file_path, 'r') as file:\n","                            data = json.load(file)\n","                            main_score = data[\"scores\"][\"test\"][0][\"main_score\"]\n","                            row[task] = main_score\n","                    except (FileNotFoundError, KeyError) as e:\n","                        print(f\"Error reading file {file_path}: {e}\")\n","                        row[task] = None\n","                scores.append(row)\n","    return scores\n","\n","def calculate_memory_used(embedding_size, quantization_method):\n","    if quantization_method == 'float32':\n","        return embedding_size * 32\n","    elif quantization_method == 'int8':\n","        return embedding_size * 8\n","    elif quantization_method == 'binary':\n","        return embedding_size * 1\n","    else:\n","        raise ValueError(f\"Unknown quantization method: {quantization_method}\")\n","\n","def calculate_averages(df, tasks_dict):\n","    df['Average_All_Tasks'] = df[tasks_dict['all']].mean(axis=1)\n","    return df\n","\n","def calculate_tradeoff_metrics(df):\n","    return df\n","\n","def generate_pandas_dataframe_accuracy_compute(base_path, model_name, dims, quantization_techniques, tasks, inference_layers, offset_path, tasks_dict):\n","    scores = get_all_scores_accuracy_compute(base_path, model_name, dims, quantization_techniques, tasks, inference_layers, offset_path)\n","    df = pd.DataFrame(scores)\n","    df = df.round(4)\n","    df = calculate_tradeoff_metrics(df)\n","    df_float32 = df[df['Quantization Technique'] == 'float32']\n","    df_int8 = df[df['Quantization Technique'] == 'int8']\n","    df_binary = df[df['Quantization Technique'] == 'binary']\n","    dataframe_to_latex(df=df_float32, test_type=\"Memory\", model_name=model_name, precision=3, caption=get_caption_memory_two_dim(model_name, \"float\"), custom_name=\"float\")\n","    dataframe_to_latex(df=df_int8, test_type=\"Memory\", model_name=model_name, precision=3, caption=get_caption_memory_two_dim(model_name, \"int\"), custom_name=\"int\")\n","    dataframe_to_latex(df=df_binary, test_type=\"Memory\", model_name=model_name, precision=3, caption=get_caption_memory_two_dim(model_name, \"binary\"), custom_name=\"binary\")\n","    return df\n","\n","def get_all_scores_accuracy_compute_averages(base_path, model_name, dims, quantization_techniques, tasks, inference_layers, offset_path, tasks_dict):\n","    scores = []\n","    for technique in quantization_techniques:\n","        for dim in dims:\n","            for layer in inference_layers:\n","                row = {\n","                    'Quantization Technique': technique,\n","                    'Dimensionality': dim,\n","                    'Inference Layer': layer,\n","                    'Memory Used (bits)': calculate_memory_used(dim, technique)\n","                }\n","                task_category_averages = {category: [] for category in tasks_dict}\n","                all_task_scores = []\n","                for task in tasks:\n","                    subfolder = f\"{model_name}_{dim}_{technique}_{layer}\"\n","                    file_path = os.path.join(base_path, subfolder, offset_path, f\"{task}.json\")\n","                    try:\n","                        with open(file_path, 'r') as file:\n","                            data = json.load(file)\n","                            main_score = data[\"scores\"][\"test\"][0][\"main_score\"]\n","                            all_task_scores.append(main_score)\n","                            for category, task_list in tasks_dict.items():\n","                                if task in task_list:\n","                                    task_category_averages[category].append(main_score)\n","                    except (FileNotFoundError, KeyError) as e:\n","                        print(f\"Error reading file {file_path}: {e}\")\n","                for category, scores_list in task_category_averages.items():\n","                    if scores_list:\n","                        row[f'Average_{category}'] = sum(scores_list) / len(scores_list)\n","                    else:\n","                        row[f'Average_{category}'] = None\n","                scores.append(row)\n","    return scores\n","\n","def generate_pandas_dataframe_accuracy_compute_averages(base_path, model_name, dims, quantization_techniques, tasks, inference_layers, offset_path, tasks_dict):\n","    scores = get_all_scores_accuracy_compute_averages(base_path, model_name, dims, quantization_techniques, tasks, inference_layers, offset_path, tasks_dict)\n","    df = pd.DataFrame(scores)\n","    df = df.round(4)\n","    dataframe_to_latex(df=df, test_type=\"MemoryAvg\", model_name=model_name, precision=3, caption=get_caption_memory_avg_two_dim(model_name))\n","    return df\n","\n","def generate_pandas_dataframe_relative_scores(base_path, model_name, dims, quantization_techniques, tasks, inference_layers, offset_path, tasks_dict):\n","    scores = get_all_scores_accuracy_compute(base_path, model_name, dims, quantization_techniques, tasks, inference_layers, offset_path)\n","    df = pd.DataFrame(scores)\n","    max_dim = max(dims)\n","    last_layer = inference_layers[0] \n","    baseline_filter = (df['Dimensionality'] == max_dim) & (df['Quantization Technique'] == 'float32') & (df['Inference Layer'] == last_layer)\n","    baseline_df = df[baseline_filter]\n","    baseline_scores = {}\n","    for task in tasks:\n","        baseline_scores[task] = baseline_df[task].values[0] if task in baseline_df.columns else None\n","    for task in tasks:\n","        if task in df.columns:\n","            df[f'Relative_{task}'] = df[task] / baseline_scores[task]\n","    relative_columns = [col for col in df.columns if col.startswith('Relative_')]\n","    df_relative_scores = df[['Quantization Technique', 'Dimensionality', 'Inference Layer', 'Memory Used (bits)'] + relative_columns]\n","    df_relative_scores = df_relative_scores.round(4)\n","    df_float32 = df_relative_scores[df_relative_scores['Quantization Technique'] == 'float32']\n","    df_int8 = df_relative_scores[df_relative_scores['Quantization Technique'] == 'int8']\n","    df_binary = df_relative_scores[df_relative_scores['Quantization Technique'] == 'binary']\n","    dataframe_to_latex(df=df_float32, test_type=\"RelativeScores\", model_name=model_name, precision=3, caption=get_caption_memory_relative_two_dim(model_name, \"float\"), custom_name=\"float\", replace_relative=True)\n","    dataframe_to_latex(df=df_int8, test_type=\"RelativeScores\", model_name=model_name, precision=3, caption=get_caption_memory_relative_two_dim(model_name, \"int\"), custom_name=\"int\", replace_relative=True)\n","    dataframe_to_latex(df=df_binary, test_type=\"RelativeScores\", model_name=model_name, precision=3, caption=get_caption_memory_relative_two_dim(model_name, \"binary\"), custom_name=\"binary\", replace_relative=True)\n","    return df_relative_scores\n","\n","\n","def generate_pandas_dataframe_scores_average_relative(base_path, model_name, dims, quantization_techniques, tasks, inference_layers, offset_path, tasks_dict):\n","    df_relative_scores = generate_pandas_dataframe_relative_scores(base_path, model_name, dims, quantization_techniques, tasks, inference_layers, offset_path, tasks_dict)\n","    for category, task_list in tasks_dict.items():\n","        relative_task_columns = [f'Relative_{task}' for task in task_list if f'Relative_{task}' in df_relative_scores.columns]\n","        if relative_task_columns:\n","            df_relative_scores[f'Average_Relative_{category}'] = df_relative_scores[relative_task_columns].mean(axis=1)\n","    average_columns = [col for col in df_relative_scores.columns if col.startswith('Average_Relative_')]\n","    df_avg_relative_only = df_relative_scores[['Quantization Technique', 'Dimensionality', 'Inference Layer', 'Memory Used (bits)'] + average_columns]\n","    df_avg_relative_only = df_avg_relative_only.round(4)\n","    dataframe_to_latex(df=df_avg_relative_only, test_type=\"AverageRelativeScores\", model_name=model_name, precision=3, caption=get_caption_memory_avg_relative_two_dim(model_name))\n","    return df_avg_relative_only\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"2pkZhSlY4w2q"},"outputs":[],"source":["df_mem_mbaii = generate_pandas_dataframe_accuracy_compute(MODEL_BASE_PATH, MODEL_NAME, dims, quantization_techniques, tasks_dict[\"all\"], INFERENCE_LAYERS, MODEL_OFFSET_PATH, tasks_dict)\n","display(df_mem_mbaii)"]},{"cell_type":"markdown","metadata":{"id":"TURaQafyFvjS"},"source":["### Average"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"M_l8xwRd4w2r"},"outputs":[],"source":["df_mem_mbaii_avg = generate_pandas_dataframe_accuracy_compute_averages(MODEL_BASE_PATH, MODEL_NAME, dims, quantization_techniques, tasks_dict[\"all\"], INFERENCE_LAYERS, MODEL_OFFSET_PATH, tasks_dict)\n","display(df_mem_mbaii_avg)"]},{"cell_type":"markdown","metadata":{"id":"l-o4CmTTEZ8S"},"source":["### Relative"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"91jwRqcJEbMG"},"outputs":[],"source":["df_relative_scores_stella = generate_pandas_dataframe_relative_scores(MODEL_BASE_PATH, MODEL_NAME, dims, quantization_techniques, tasks_dict[\"all\"], INFERENCE_LAYERS, MODEL_OFFSET_PATH, tasks_dict)\n","display(df_relative_scores_stella)"]},{"cell_type":"markdown","metadata":{"id":"-ZbLlDSFEc52"},"source":["### Average Relative"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"mC1IME_FEeRj"},"outputs":[],"source":["df_avg_relative_scores_stella = generate_pandas_dataframe_scores_average_relative(MODEL_BASE_PATH, MODEL_NAME, dims, quantization_techniques, tasks_dict[\"all\"], INFERENCE_LAYERS, MODEL_OFFSET_PATH, tasks_dict)\n","display(df_avg_relative_scores_stella)"]},{"cell_type":"markdown","metadata":{"id":"H0dg6x1iumS1"},"source":["# Co2 Emissions"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"hgh7NUTHuprJ"},"outputs":[],"source":["def sum_total_times(dataframes):\n","    total_sums = []\n","    overall_total_time = 0\n","    for i, df in enumerate(dataframes):\n","        if 'Total_Time' in df.columns:\n","            total_sum = df['Total_Time'].sum()\n","            total_sums.append(total_sum)\n","            overall_total_time += total_sum\n","            print(f\"Total Time for DataFrame {i+1}: {total_sum:.2f} seconds ({total_sum/3600.0} hours)\")\n","        else:\n","            total_sums.append(0)\n","            print(f\"DataFrame {i+1} does not have a Total_Time column.\")\n","\n","    print(f\"\\nOverall Total Time for all DataFrames: {overall_total_time:.2f} seconds ({overall_total_time/3600.0} hours)\")\n","    return total_sums, overall_total_time"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"flINoa2RxpZk"},"outputs":[],"source":["dfs_co2 = [df_time_stella, df_time_nomic, df_time_mbai, df_time_mbaii]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"njh2WwcH4435"},"outputs":[],"source":["sum_total_times(dfs_co2)"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyNyy7cOFkmqZh0YVml9Hy67","collapsed_sections":["4l-ggqZ__ruW","P-seXKIEANNy"],"name":"","provenance":[{"file_id":"1jXwBi1b9r6LWyL-xXKjYhaLAi3Ryo5Yp","timestamp":1722943796189}],"toc_visible":true,"version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
